{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05c6a0-a5b7-459d-95cb-810afe750ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau, StepLR\n",
    "from torch.optim import RAdam\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence, PackedSequence\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "from utils.model import *\n",
    "from utils.attention import BadhanauAttention\n",
    "\n",
    "from utils.dataset import CommonVoice\n",
    "from utils.audio_utils import plot_waveform, play_audio\n",
    "from utils.batch_utils import Collator\n",
    "from utils.tokenizer import get_tokenizer\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc5281-1c6f-490f-b2de-72d7c9187fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f237251-1e2f-402f-a0b0-995c07bf1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.misc import get_summary, get_writer\n",
    "from utils.grad_flow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446aac2-89a2-4747-bb36-41fedc0ef545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pkbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6071366-8bd4-490f-800d-64e0439b3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0 \n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110dab0c-10b1-4665-8726-cc37bcfd6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2acde-600e-4545-9207-76b48e5abe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'data/external/cv-corpus-8.0-2022-01-19/en/'\n",
    "\n",
    "tokenizer_file = 'data/tokenizer/trained_tokenizer.json'\n",
    "\n",
    "trimmed_train_path = 'data/internal/sample_train.tsv'\n",
    "# trimmed_train_path = 'data/internal/train_trimmed.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f89b6-6c88-4763-a927-e2f8b8d1b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(tokenizer_file_path=tokenizer_file)\n",
    "\n",
    "blank_token_id = tokenizer.vocab[\"[BLANK]\"]\n",
    "bos_token_id = tokenizer.vocab[\"[BOS]\"]\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230b8ef-817a-4449-a113-19dc2518c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CommonVoice(dataset_dir = dataset_dir, subset_path = trimmed_train_path, tokenizer = tokenizer, out_channels = 1)\n",
    "# train_data = CommonVoice(dataset_dir = dataset_dir, subset_name = 'train', tokenizer = tokenizer, out_channels = 1)\n",
    "\n",
    "dev_data = CommonVoice(dataset_dir = dataset_dir, subset_name = 'dev', tokenizer = tokenizer, out_channels = 1)\n",
    "\n",
    "print(train_data)\n",
    "\n",
    "print(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb0b01-e6a7-4d25-a816-f00c0c4951db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'encoder_input_size': 80,\n",
    "    'conformer_num_heads': 4,\n",
    "    'conformer_ffn_size': 512,\n",
    "    'conformer_num_layers': 16,\n",
    "    'conformer_conv_kernel_size': 31,\n",
    "    'encoder_rnn_hidden_size': 1024,\n",
    "    'encoder_rnn_num_layers': 1,\n",
    "    'encoder_rnn_bidirectional': True,\n",
    "    'decoder_embedding_size': 300,\n",
    "    'decoder_hidden_size': 1024,\n",
    "    'decoder_num_layers': 1,\n",
    "    'decoder_attn_size': 144,\n",
    "    'dropout': 0.3,\n",
    "    'padding_idx': tokenizer.pad_token_id,\n",
    "    'sos_token_id': tokenizer.bos_token_id,\n",
    "    'vocab_size': vocab_size,\n",
    "    'batch_first': True,\n",
    "    'device': device,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5065e96-6ddb-464a-bee0-0f9a8620e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = Collator(tokenizer)\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_loader = DataLoader(train_data, \n",
    "                          batch_size = BATCH_SIZE, \n",
    "                          collate_fn=collator, \n",
    "                          shuffle=True, \n",
    "                          pin_memory = False, \n",
    "                          num_workers = 12, \n",
    "                          worker_init_fn = collator.seed_worker, \n",
    "                          generator = g)\n",
    "\n",
    "fp16 = False\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64596bb5-5ab5-4bab-8f4d-b8fdc3b2ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(**model_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a8d1d-6e5b-4f9b-8be0-cee5d214c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_summary(encoder, dataloader = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe92141-a09d-48b5-9255-ef5771531510",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CTC loss should be computed after the encoder outputs the probabilities\n",
    "\n",
    "## Decoding part is usually decoupled from encoding part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b2157-d7ea-4a3c-b8e2-b036fa743f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_log_dir = 'logs/'\n",
    "writer = get_writer(base_log_dir=base_log_dir)\n",
    "# writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd7f24-9117-4dbc-aef4-f169695307e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_batch(batch: Dict, max_len: int = 50):\n",
    "    \n",
    "    melspec = batch['melspecs'].to(device).squeeze(0)\n",
    "    melspecs_lengths = batch['melspecs_lengths'].to(device, dtype = torch.int32)\n",
    "    \n",
    "    sentences = batch['sentences'].to(device)\n",
    "    sentence_lengths = torch.LongTensor(batch['sentence_lengths']).to(device=device)    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ##Change from [batch, feats, seq_len] to [batch, seq_len,featrs]\n",
    "        predicted_tensor = model.forward(melspec.permute(0,2,1), melspecs_lengths, sentences, sentence_lengths)\n",
    "        y_ids = predicted_tensor.argmax(dim = -1)\n",
    "        y_pred = torch.unique_consecutive(y_ids, dim = 1)\n",
    "        \n",
    "        y_pred = tokenizer.batch_decode(y_pred)\n",
    "    \n",
    "    y_true = tokenizer.batch_decode(sentences)\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33cf11-0a82-4892-a25d-b7f6aea3b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "try:\n",
    "    samples\n",
    "except NameError as e:\n",
    "    samples = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175e987-149c-4617-ad32-a13756bbaa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "lr = 3e-5  # learning rate\n",
    "\n",
    "MAX_NORM = 0.5\n",
    "\n",
    "num_batches = len(train_loader)\n",
    "\n",
    "# optim = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "# optim = torch.optim.RAdam(model.parameters(), lr = lr)\n",
    "optim = torch.optim.RAdam(model.parameters())\n",
    "scheduler_plateau = ReduceLROnPlateau(optim, mode = 'min', patience = 2)\n",
    "\n",
    "scheduler_stepLR = StepLR(optim, 1.0, gamma=0.95)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "criterion = nn.NLLLoss(ignore_index=tokenizer.pad_token_id)\n",
    "# criterion = nn.CTCLoss(blank = tokenizer.vocab['[BLANK]'], \n",
    "#                      zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a0551-4b8c-4a79-b46c-53157937eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch: List[Dict[str, torch.Tensor]], n_iter: int, MAX_NORM: float = 0.5, plot_gradients: bool = True):\n",
    "    \n",
    "    optim.zero_grad(set_to_none = True)\n",
    "    \n",
    "    sentences = batch['sentences'].to(device)\n",
    "    sentence_lengths = batch['sentence_lengths'].to(device, dtype = torch.int32)\n",
    "\n",
    "    melspecs = batch['melspecs'].to(device)\n",
    "    melspecs_lengths = batch['melspecs_lengths'].to(device, dtype = torch.int32)\n",
    "\n",
    "    melspecs = torch.transpose(melspecs, -1, -2) ## Changing to (batch, channel, time, n_mels) from (batch, channel, n_mels, time)\n",
    "\n",
    "    predicted_tensor = model.forward(melspecs, melspecs_lengths, sentences, sentence_lengths)\n",
    "    \n",
    "    y_pred = predicted_tensor.reshape(-1, vocab_size)\n",
    "    y_true = sentences[:, 1:].reshape(-1)  ##Skip the <sos> token from the targets \n",
    "        \n",
    "    loss = criterion( input = y_pred, target = y_true )       \n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    ## Plot Gradients every 10 steps\n",
    "    if n_iter % 10 == 0 and plot_gradients == True:\n",
    "\n",
    "        grad_flow_fig = plot_grad_flow_v2(model.named_parameters())\n",
    "    \n",
    "    else:\n",
    "        grad_flow_fig = None\n",
    "    \n",
    "    ## Gradient Clipping for exploding gradients\n",
    "    clip_grad_norm_(model.parameters(), max_norm = MAX_NORM)\n",
    "\n",
    "    ## Step the optimizers\n",
    "    optim.step()\n",
    "\n",
    "    ## Step the schedulers\n",
    "    scheduler_stepLR.step()\n",
    "\n",
    "    return loss.detach().cpu().item(), grad_flow_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4acc4f9-c9e2-4234-8fa6-9961c01e082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 0\n",
    "\n",
    "y_true, _ = predict_one_batch(samples)\n",
    "writer.add_text('y_true sentence', y_true[0], global_step = n_iter)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    kbar = pkbar.Kbar(target = num_batches, epoch = epoch, num_epochs=EPOCHS, width = 8, always_stateful=False)\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        optim.zero_grad(set_to_none=True)\n",
    "\n",
    "        loss, grad_flow_fig = train_step(batch, n_iter, plot_gradients=True)\n",
    "        \n",
    "        ## Write how sample is being predicted\n",
    "        ##predict_one_batch uses no grad\n",
    "        _, sample_pred = predict_one_batch(samples)\n",
    "        writer.add_text('y_pred sentence', sample_pred[0], global_step = n_iter)\n",
    "        \n",
    "        writer.add_scalar('CE Loss/train', loss, n_iter)\n",
    "        \n",
    "        if grad_flow_fig != None:\n",
    "            \n",
    "            writer.add_figure('Average Gradients/Model', grad_flow_fig, global_step = n_iter, close = True)\n",
    "\n",
    "        kbar.update(idx, values = [(\"loss\", loss)])\n",
    "\n",
    "        n_iter += 1\n",
    "    \n",
    "    ## At epoch end\n",
    "    \n",
    "    scheduler_plateau.step(loss)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bdb18-08cf-4b89-bab6-112348dea975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8376296fdecafa8d748ac5b3740e0b8e6dc4d67dae6152bd741e7a91aa957642"
  },
  "kernelspec": {
   "display_name": "Speech",
   "language": "python",
   "name": "speech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
